DataEngineering_TWSE_TPEX
Automated Taiwan Stock Market Data Pipeline (TWSE & TPEX)

ğŸ§© Overview
This project builds an automated distributed ETL pipeline for collecting, cleaning, and storing daily stock data from both the Taiwan Stock Exchange (TWSE) and the Taipei Exchange (TPEX).

It uses Apache Airflow (CeleryExecutor) for orchestration, Redis as the message broker and result backend, and Docker Swarm to manage containers across multiple nodes. All cleaned data is stored in MySQL, and task monitoring is provided via Flower.

âš™ï¸ Architecture

ğŸ—‚ Project Structure
DataEngineering_twse_tpex/
â”œâ”€â”€ airflow.yml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ dataflow/
â”‚   â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ dags/
â”‚   â””â”€â”€ schema/
â”œâ”€â”€ Makefile
â””â”€â”€ requirements.txt
ğŸš€ Workflow Summary
1ï¸âƒ£ Airflow Scheduler triggers daily DAGs. 2ï¸âƒ£ Tasks are sent to the Redis queue. 3ï¸âƒ£ Celery Workers execute crawlers. 4ï¸âƒ£ Fetch TWSE/TPEX data. 5ï¸âƒ£ Clean, validate, and upload to MySQL. 6ï¸âƒ£ Flower monitors the workers and queue. 7ï¸âƒ£ (Optional) FastAPI provides data query endpoints.

ğŸ§  Tech Stack
Category	Tool
Orchestration	Apache Airflow (CeleryExecutor)
Broker / Backend	Redis 5.0
Database	MySQL 8.0
Monitoring	Flower
Language	Python 3.11
Framework	pandas, SQLAlchemy, Pydantic
Container Management	Docker Swarm
ğŸ³ Docker Swarm Deployment Example
docker stack deploy -c airflow.yml airflow
docker service ls
docker service ps airflow_webserver
ğŸª¶ Example Access
Component	URL	Description
Airflow UI	http://:8888	DAG monitoring
Flower	http://:5555	Task queue status
MySQL	mysql://:3306	Data storage
